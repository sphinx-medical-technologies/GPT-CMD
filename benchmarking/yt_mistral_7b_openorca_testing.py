# -*- coding: utf-8 -*-
"""YT Mistral-7B-OpenOrca - Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1im-yA1k9l-2UIvbmsf2Q10Y_wkAQvQqs
"""

!pip install git+https://github.com/huggingface/transformers # need to install from github
!pip install datasets loralib sentencepiece
!pip install bitsandbytes accelerate xformers einops
!pip install langchain

"""https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca

## Open-Orca/Mistral-7B-OpenOrca
"""

import torch
import transformers
from transformers import AutoTokenizer, AutoModelForCausalLM

torch.set_default_device('cuda')

model = AutoModelForCausalLM.from_pretrained("Open-Orca/Mistral-7B-OpenOrca",
                                             torch_dtype="auto")

tokenizer = AutoTokenizer.from_pretrained("Open-Orca/Mistral-7B-OpenOrca",
                                          torch_dtype="auto")

text = """<|im_start|>system\n
You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!\n
<|im_end|>\n
<|im_start|>user\n
what is the meaning of life?\n
<|im_end|>"""

encodeds = tokenizer(text, return_tensors="pt", add_special_tokens=False)

device = 'cuda'
model_inputs = encodeds.to(device)
model.to(device)

generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)
decoded = tokenizer.batch_decode(generated_ids)
print(decoded[0])

"""### Prompt Format
```
<|im_start|>system
You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!
<|im_end|>
<|im_start|>user
How are you?<|im_end|>
<|im_start|>assistant
I am doing well!<|im_end|>
<|im_start|>user
Please tell me about how mistral winds have attracted super-orcas.<|im_end|>

```
"""

import textwrap

def wrap_text(text, width=90): #preserve_newlines
    # Split the input text into lines based on newline characters
    lines = text.split('\n')

    # Wrap each line individually
    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]

    # Join the wrapped lines back together using newline characters
    wrapped_text = '\n'.join(wrapped_lines)

    return wrapped_text

def generate(input_text, system_prompt="",max_length=512):
    if system_prompt != "":
        system_prompt = f"""<|im_start|> system\n{system_prompt}<|im_end|>"""
    else:
        system_prompt = ""
    prompt = f"""<|im_start|> user\n{input_text}<|im_end|>"""
    final_prompt = system_prompt + prompt
    inputs = tokenizer(final_prompt, return_tensors="pt", add_special_tokens=False)
    model_inputs = encodeds.to(device)
    model.to(device)
    outputs = model.generate(**inputs,
                             max_length=max_length,
                             temperature=0.1,
                             pad_token_id = 3200,
                             do_sample=True)
    text = tokenizer.batch_decode(outputs)[0]
    # text = text[len(final_prompt):] if text.startswith(final_prompt) else text
    text = text.replace(final_prompt, '', 1)
    wrapped_text = wrap_text(text)
    print(wrapped_text)

"""## CodeGen"""

generate('''```python
def print_prime(n):
   """
   Print all primes between 1 and n
   """''', system_prompt="You are a genius python coder")

generate('''```python
def detect_prime(n):
   """
   detect if a number is a prime number or not. return True or False
   """''', system_prompt="You are a genius python coder")

"""## Instruction Answering"""

generate('Write a detailed analogy between mathematics and a lighthouse.',
         system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
         max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Write a detailed analogy between mathematics and a music.',
#          system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
#          max_length=256)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('What is the difference between a Llama, Vicuna and an Alpaca?',
#          system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Write a short email to Sam Altman giving reasons to open source GPT-4',
#          system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Write a short email to Sam Altman giving reasons to open source GPT-4',
#          system_prompt="You are Freddy a young 5 year old boy who is scared AI will end the world, write only with the language of a young child!",
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Write a short email to Sam Altman giving reasons to open source GPT-4',
#          system_prompt="You are Kate, the Vice president of USA, you are against regulatory capture and like to explain that!",
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('What is the capital of England?',
#          system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your short and succinct!",
#          max_length=256)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Can Geoffrey Hinton have a conversation with George Washington? Give the rationale before answering.',
#          system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
#          max_length=512)

generate('Write a story about a Koala playing pool and beating all the camelids.',
         system_prompt="You are MistralOrca, a genius story teller. Write out your with details and make it compelling!",
         max_length=1024)

"""## Chat"""

generate("""Alice: I don't know why, I'm struggling to maintain focus while studying. Any suggestion? \n\n Bob:""",
         system_prompt="You are MistralOrca, a LLM that generates great conversations. continue as Bob here",
         max_length=512)

"""## GSM8K"""

generate('Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?',
         system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
         max_length=256)

generate("Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?",
         system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
         max_length=512)

generate("A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?",
         system_prompt="You are MistralOrca, a large language model trained by Alignment Lab AI. Write out your reasoning step-by-step to be sure you get the right answers!",
         max_length=1024)

