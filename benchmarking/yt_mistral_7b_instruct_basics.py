# -*- coding: utf-8 -*-
"""YT Mistral 7B Instruct - Basics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14NjXdNlpevSRkifPwYZ7TfG74FVi1v0G
"""

!pip -q install git+https://github.com/huggingface/transformers # need to install from github
!pip install -q datasets loralib sentencepiece
!pip -q install bitsandbytes accelerate xformers einops
!pip -q install langchain

"""## Mistral 7B Instruct


"""

import torch
import transformers
from transformers import AutoTokenizer, AutoModelForCausalLM

torch.set_default_device('cuda')

model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1",
                                             torch_dtype="auto")

tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1",
                                          torch_dtype="auto")

text = "<s>[INST] What is your favourite condiment? [/INST]Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> [INST] Do you have mayonnaise recipes? [/INST]"

encodeds = tokenizer(text, return_tensors="pt", add_special_tokens=False)

device = 'cuda'
model_inputs = encodeds.to(device)
model.to(device)

generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True)
decoded = tokenizer.batch_decode(generated_ids)
print(decoded[0])

"""### Prompt Format
```
<s>[INST] <user_prompt> [/INST]

<assistant_response> </s>

[INST] <user_prompt>[/INST]
```
"""

import textwrap

def wrap_text(text, width=90): #preserve_newlines
    # Split the input text into lines based on newline characters
    lines = text.split('\n')

    # Wrap each line individually
    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]

    # Join the wrapped lines back together using newline characters
    wrapped_text = '\n'.join(wrapped_lines)

    return wrapped_text

def generate(input_text, system_prompt="",max_length=512):
    prompt = f"""<s>[INST]{input_text}[/INST]"""
    inputs = tokenizer(input_text, return_tensors="pt", add_special_tokens=False)
    model_inputs = encodeds.to(device)
    model.to(device)
    outputs = model.generate(**inputs,
                             max_length=max_length,
                             temperature=0.1,
                             do_sample=True)
    text = tokenizer.batch_decode(outputs)[0]
    wrapped_text = wrap_text(text)
    print(wrapped_text)

"""## CodeGen"""

generate('''```python
def print_prime(n):
   """
   Print all primes between 1 and n
   """''', system_prompt="You are a genius python coder")

generate('''```python
def detect_prime(n):
   """
   detect if a number is a prime number or not. return True or False
   """''')

"""## Instruction Answering"""

generate('What is the last name or surname in the following sentence.  Display no other text: Calling about Silva Carl, birth date sept 18th, 1963.',
         max_length=128)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('What is the first name or proper name in the following sentence.  Display no other text: Calling about Silva Carl, birth date sept 18th, 1963.',
#          max_length=256)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Display the first date of birth found in the following sentence in the format MM/DD/YYYY.  Display no other text.  Sentence: Calling about Silva Carl, birth date sept 18th, 1963.',
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Reply to the following question with either Surname, Given Name, or Unknown.  Reply with no other text.  Is the following name more commonly known as a surname or as a given name? Carl',
#          max_length=512)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Classify the following transcription into one of the following categories:\n- Doctor\n- Pharmacy\n- Patient\n- Other\nIf the transcription does not fit into any categories, classify it as the following:\n- Unknown\n  Display only the Category and no other text.  Transcription: Calling to clarify prescriptions sent over for patient Agnes Moore Sherry and mole S H I R I date of birth 100-3154 given a prescription for doxycycline high Clete 100 milligrams.  Just to dispense 1 tablet with the sig of 100 milligram as directed patients said it should be a 100 day supply. If you can please call us back our phone numbers 310-316-6849 again 310-316-6849.\nCategory:',
#          max_length=256)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# generate('Generate a summary of only five words removing all personal information for the following text: I am calling in regards to patient Addison Bryant, date of birth 10-28-2006. I was calling to obtain clarification on the patient Botox. We need a site of injection or either the ICD-10 code.',
#          max_length=256)

generate('Say in only one word and no other text what is the caller intent contained in the following transcription: Hi there, this is John Smith, um, date of birth 12-30-71, I am a patient of Dr. Lopez, um, and I was calling to see if he could authorize a refill. I am on, like, the generic Ozempic injection that I give myself weekly, and I think I have used them all up, and I was wondering if he could call in a refill of that for me. I left my cell phone number, it is 904-318-8235. Thanks a lot. Bye-bye.',
         max_length=512)

"""## Chat"""

generate("""CallMyDoc: You are a chat assistant for a telephone answering service for a doctor's office. Your goal would be to ask for: a date of birth, call back phone number, first name, last name, and their reason for calling. You will ask one question at a time.  You will provide no other assistance other than collecting information. Once you have collected the information, you will confirm that it is correct with the caller.  Afterwards, you will report the data you have collected only in CSV format with no other text.\n\n CallMyDoc:""",
         max_length=256)

generate("""Caller: My first name is Dhonn\n\nCallMyDoc:""",
         max_length=256)

"""## GSM8K"""

generate('Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?',
         max_length=256)

generate("Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?",
         max_length=128)

generate("A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?",
         max_length=256)